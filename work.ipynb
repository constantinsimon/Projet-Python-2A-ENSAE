{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc901a2",
   "metadata": {},
   "source": [
    "C'est normal d'avoir des difficult√©s avec le code, surtout sur un projet qui combine scraping, API et calculs g√©om√©triques. Pour la soutenance, ce qui compte, c'est de montrer que **vous avez compris la logique** de ce que vous faites, m√™me si le code n'est pas parfait.\n",
    "\n",
    "Voici un plan d'action en **3 √©tapes cl√©s**, avec le code pr√™t √† l'emploi et, pour chaque bloc, l'argumentaire \"Sp√©cial Soutenance\".\n",
    "\n",
    "---\n",
    "\n",
    "###√âtape 1 : R√©cup√©rer les donn√©es propres des gares (Open Data)Au lieu de scraper des coordonn√©es approximatives, on t√©l√©charge le fichier officiel de la SNCF.\n",
    "\n",
    "**Le Code (√† copier dans un nouveau notebook ou √† la suite de `main.ipynb`) :**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# 1. URL stable de l'API SNCF Open Data (export CSV)\n",
    "url_sncf = \"https://ressources.data.sncf.com/api/explore/v2.1/catalog/datasets/liste-des-gares/exports/csv\"\n",
    "\n",
    "# 2. Chargement des donn√©es\n",
    "print(\"T√©l√©chargement des donn√©es SNCF en cours...\")\n",
    "df_sncf = pd.read_csv(url_sncf, sep=\";\")\n",
    "\n",
    "# 3. Extraction et nettoyage des coordonn√©es\n",
    "# On ne garde que le nom et la position. Le format est souvent \"Lat, Lon\" dans une seule colonne.\n",
    "df_gares_final = df_sncf[['libelle', 'geo_point_2d']].dropna().copy()\n",
    "\n",
    "# 4. S√©paration de la colonne unique \"48.85, 2.35\" en deux colonnes num√©riques\n",
    "df_gares_final[['Lat', 'Lon']] = df_gares_final['geo_point_2d'].str.split(',', expand=True).astype(float)\n",
    "\n",
    "# 5. Renommer pour √™tre clair\n",
    "df_gares_final = df_gares_final.rename(columns={'libelle': 'Nom_Gare'})\n",
    "\n",
    "print(f\"Nombre de gares r√©cup√©r√©es : {len(df_gares_final)}\")\n",
    "df_gares_final.head()\n",
    "\n",
    "```\n",
    "\n",
    "####üéì L'Explication pour la Soutenance (Ligne par Ligne)* **Ligne 1 (`url_sncf = ...`)** : *\"Nous avons choisi d'utiliser l'API Open Data de la SNCF plut√¥t que le scraping pour les coordonn√©es g√©ographiques.\"*\n",
    "* **Justification :** C'est une source **officielle** (fiabilit√©) et **stable** (le code ne cassera pas si Wikip√©dia change son design).\n",
    "\n",
    "\n",
    "* **Ligne 2 (`pd.read_csv(..., sep=\";\")`)** : *\"On charge directement le CSV depuis l'URL.\"*\n",
    "* **Justification :** Le s√©parateur est `;` car les CSV fran√ßais utilisent souvent la virgule pour les d√©cimales.\n",
    "\n",
    "\n",
    "* **Ligne 3 (`dropna()`)** : *\"On supprime les lignes vides.\"*\n",
    "* **Justification :** Une gare sans coordonn√©es GPS est inutile pour notre mod√®le, on nettoie les donn√©es d√®s l'entr√©e.\n",
    "\n",
    "\n",
    "* **Ligne 4 (`str.split`)** : *\"On s√©pare la cha√Æne de caract√®res g√©ographique en deux nombres flottants (latitude et longitude).\"*\n",
    "* **Justification :** Pour faire des calculs math√©matiques de distance, l'ordinateur a besoin de deux nombres distincts, pas d'une phrase textuelle.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###√âtape 2 : Le c≈ìur du projet - Calculer la distance (BallTree)C'est l'√©tape la plus technique. Vous avez 300 000 transactions immobili√®res et 2 000 gares.\n",
    "Si vous faites une boucle simple (`pour chaque maison, regarde toutes les gares`), l'ordinateur va faire 300 000 x 2 000 = **600 millions d'op√©rations**. √áa prendra des heures. On utilise donc un algorithme optimis√© : le **BallTree**.\n",
    "\n",
    "**Le Code :**\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que 'df2' est votre DataFrame immobilier nettoy√© contenant 'lat' et 'lon'\n",
    "# et 'df_gares_final' est celui de l'√©tape 1\n",
    "\n",
    "# 1. Conversion des coordonn√©es en radians\n",
    "# La Terre est une sph√®re, les maths marchent en radians, pas en degr√©s.\n",
    "gps_gares = np.radians(df_gares_final[['Lat', 'Lon']].values)\n",
    "gps_immo = np.radians(df2[['lat', 'lon']].values) # Assurez-vous d'avoir ces colonnes dans df2\n",
    "\n",
    "# 2. Construction de l'arbre (Indexation spatiale)\n",
    "tree = BallTree(gps_gares, metric='haversine')\n",
    "\n",
    "# 3. Requ√™te pour trouver le plus proche voisin (k=1)\n",
    "# Cela renvoie la distance et l'index de la gare la plus proche\n",
    "distances, indices = tree.query(gps_immo, k=1)\n",
    "\n",
    "# 4. Conversion de la distance (radians -> km)\n",
    "# Rayon de la Terre approx = 6371 km\n",
    "df2['distance_gare_km'] = distances * 6371\n",
    "\n",
    "# 5. R√©cup√©ration du nom de la gare la plus proche\n",
    "# On utilise les indices trouv√©s par l'arbre pour aller chercher le nom dans le dataframe des gares\n",
    "df2['gare_proche'] = df_gares_final.iloc[indices.flatten()]['Nom_Gare'].values\n",
    "\n",
    "print(df2[['adresse', 'gare_proche', 'distance_gare_km']].head())\n",
    "\n",
    "```\n",
    "\n",
    "####üéì L'Explication pour la Soutenance* **Ligne 1 (`np.radians`)** : *\"Nous convertissons les degr√©s GPS en radians.\"*\n",
    "* **Justification :** Les formules de trigonom√©trie sph√©rique (pour calculer une distance sur une sph√®re comme la Terre) fonctionnent en radians.\n",
    "\n",
    "\n",
    "* **Ligne 2 (`BallTree`)** : *\"Nous construisons une structure de donn√©es en arbre, appel√©e BallTree.\"*\n",
    "* **Justification (CL√â pour la note) :** C'est un choix d'**optimisation algorithmique**. Au lieu de calculer b√™tement toutes les distances (complexit√© O(N*M)), l'arbre permet de diviser l'espace et de trouver le voisin le plus proche tr√®s vite (complexit√© logarithmique O(log N)). C'est ce qui rend le code ex√©cutable sur un gros dataset.\n",
    "\n",
    "\n",
    "* **Ligne 3 (`metric='haversine'`)** : *\"On utilise la formule de Haversine.\"*\n",
    "* **Justification :** C'est la formule math√©matique qui calcule la distance \"√† vol d'oiseau\" sur une sph√®re, tenant compte de la courbure de la Terre.\n",
    "\n",
    "\n",
    "* **Ligne 4 (`k=1`)** : *\"On demande seulement le 1er voisin.\"*\n",
    "* **Justification :** On ne veut que la gare la plus proche, pas les 10 plus proches.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###√âtape 3 : La brique \"Scraping\" (Pour valider le cours)Puisque vous avez \"trich√©\" (intelligemment) √† l'√©tape 1 en prenant l'Open Data, il faut montrer au jury que vous savez quand m√™me scraper.\n",
    "Nous allons scraper **la population des pr√©fectures** sur Wikip√©dia pour voir si le prix d√©pend aussi de la taille de la ville (et pas juste du TGV).\n",
    "\n",
    "**Le Code :**\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_population_wikipedia(ville):\n",
    "    # 1. Construction de l'URL Wikip√©dia\n",
    "    # On remplace les espaces par des underscores (ex: \"Bourg en Bresse\" -> \"Bourg_en_Bresse\")\n",
    "    base_url = \"https://fr.wikipedia.org/wiki/\"\n",
    "    url = base_url + ville.replace(\" \", \"_\")\n",
    "\n",
    "    try:\n",
    "        # 2. Requ√™te HTTP\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "\n",
    "        # 3. Parsing HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 4. Recherche de l'Infobox (le tableau r√©capitulatif √† droite sur Wikip√©dia)\n",
    "        infobox = soup.find(\"div\", {\"class\": \"infobox_v3\"})\n",
    "\n",
    "        # 5. Recherche de la ligne \"Population\"\n",
    "        # C'est du scraping \"artisanal\" : on cherche le texte qui contient \"Population\"\n",
    "        rows = infobox.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            if \"Population\" in row.text:\n",
    "                # On nettoie le texte (enl√®ve les espaces ins√©cables, etc)\n",
    "                return row.text.split(\"hab.\")[0].replace(\"\\xa0\", \"\").replace(\" \", \"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Test sur une ville\n",
    "pop = get_population_wikipedia(\"Lyon\")\n",
    "print(f\"Population scrap√©e : {pop}\")\n",
    "\n",
    "```\n",
    "\n",
    "####üéì L'Explication pour la Soutenance* **Ligne 1 (URL)** : *\"On dynamise l'URL.\"*\n",
    "* **Justification :** Wikip√©dia a une structure d'URL pr√©visible, ce qui nous permet d'automatiser la recherche par nom de ville.\n",
    "\n",
    "\n",
    "* **Ligne 3 (`BeautifulSoup`)** : *\"On utilise la librairie BS4 pour transformer le HTML brut en objet navigable.\"*\n",
    "* **Ligne 4 (`infobox_v3`)** : *\"On cible la classe CSS sp√©cifique.\"*\n",
    "* **Justification :** Apr√®s avoir inspect√© le code source de la page (F12), on a remarqu√© que les donn√©es cl√©s sont toujours dans une `div` appel√©e `infobox_v3` ou `infobox`. Cela limite la recherche et √©vite de lire tout le texte de l'article.\n",
    "\n",
    "\n",
    "* **Gestion des erreurs (`try/except`)** : *\"On a ajout√© une gestion d'erreurs.\"*\n",
    "* **Justification :** En scraping, les pages sont h√©t√©rog√®nes. Si une page n'existe pas ou n'a pas d'infobox, le code ne doit pas planter, il doit juste renvoyer `None` et passer √† la suivante.\n",
    "\n",
    "\n",
    "\n",
    "###R√©sum√© pour votre projet1. Lancez le code de l'**√âtape 1** pour avoir `df_gares_final`.\n",
    "2. Assurez-vous que votre `df2` (immobilier) a bien des colonnes `lat` et `lon`.\n",
    "* *Attention :* Dans votre `main.ipynb`, vous g√©ocodez ligne par ligne avec une boucle. Pour 300 000 lignes, **√ßa va planter**.\n",
    "* *Conseil d'ami :* Pour le projet, travaillez sur un **√©chantillon** (ex: `df2 = df2.sample(10000)`). Expliquez √† la soutenance que vous avez r√©duit la taille pour des raisons de performance de l'API de g√©ocodage, mais que le code marcherait sur tout le fichier avec plus de temps.\n",
    "\n",
    "\n",
    "3. Lancez le code de l'**√âtape 2** pour ajouter la colonne `distance_gare_km` √† votre √©chantillon.\n",
    "4. Faites un graphique simple (nuage de points : axe X = distance, axe Y = prix m2).\n",
    "\n",
    "Est-ce que ces explications vous semblent claires pour les pr√©senter ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7752cbca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
