{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e20756",
   "metadata": {},
   "source": [
    "# Analyse des transactions immobilières en France  \n",
    "*Une approche par les caractéristiques du logement, le contexte géographique et la proximité aux gares SNCF*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27431409",
   "metadata": {},
   "source": [
    "## 1. Données et préparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98be7a9",
   "metadata": {},
   "source": [
    "### 1.1 Chargement et nettoyage initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On effectue les importations basiques utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Chemin vers le fichier DVF (données des transactions immobilières)\n",
    "FILE_PATH = \"/home/onyxia/work/Projet-Python-2A-ENSAE/ValeursFoncieres-2025-S1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1ERE LECTURE DU FICHIER DVF ---\n",
    "\n",
    "# On lit le fichier CSV avec pandas\n",
    "df = pd.read_csv(\n",
    "    FILE_PATH,       \n",
    "    sep=\"|\",        \n",
    "    dtype=str,         \n",
    "    decimal=\",\",       \n",
    "    na_values=[\"\", \" \"],  # les champs vides sont considérés comme des valeurs manquantes\n",
    "    engine=\"python\"    \n",
    ")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NETTOYAGE DE BASE DES VARIABLES ---\n",
    "\n",
    "df[\"Date mutation\"] = pd.to_datetime(\n",
    "    df[\"Date mutation\"],\n",
    "    format=\"%d/%m/%Y\",\n",
    "    errors=\"coerce\"    # les dates invalides deviennent NaT\n",
    ")\n",
    "\n",
    "df[\"Valeur fonciere\"] = (\n",
    "    df[\"Valeur fonciere\"]\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"Surface terrain\"] = pd.to_numeric(\n",
    "    df[\"Surface terrain\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "df[\"Surface reelle bati\"] = pd.to_numeric(\n",
    "    df[\"Surface reelle bati\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "df[\"Nombre pieces principales\"] = pd.to_numeric(\n",
    "    df[\"Nombre pieces principales\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "\n",
    "\n",
    "# --- OPTIONS D’AFFICHAGE ---\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 2000)\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "\n",
    "\n",
    "# --- VÉRIFICATIONS DE BASE ---\n",
    "\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(f\"Nombre de lignes : {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d684eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime les biens dont la surface bâtie, et la valeur foncière, est négative ou nulle\n",
    "df = df[(df[\"Surface reelle bati\"] > 0) & (df[\"Valeur fonciere\"] > 0)]\n",
    "\n",
    "print(f\"Nombre de lignes : {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes jugées non pertinentes pour l'analyse économique\n",
    "colonnes_hors_perimetre = [\n",
    "    \"1 Articles CGI\",\n",
    "    \"2 Articles CGI\",\n",
    "    \"3 Articles CGI\",\n",
    "    \"4 Articles CGI\",\n",
    "    \"5 Articles CGI\",\n",
    "    \"Identifiant de document\",\n",
    "    \"Reference document\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=colonnes_hors_perimetre, errors='ignore') # ignore pour quand on relance\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comptage des types de locaux présents dans la base\n",
    "df[\"Type local\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f18c73",
   "metadata": {},
   "source": [
    "### 1.2 Définition du périmètre d’étude\n",
    "\n",
    "La base DVF contient à la fois des biens résidentiels et des biens non résidentiels\n",
    "(locaux industriels, commerciaux ou assimilés).\n",
    "\n",
    "Dans ce projet, nous nous concentrons exclusivement sur le **marché du logement**.\n",
    "Nous restreignons donc l’échantillon aux **maisons et appartements**, en nous appuyant\n",
    "sur la variable *Type local*.\n",
    "\n",
    "Ce filtrage permet d’éviter que des biens atypiques (entrepôts, locaux commerciaux,\n",
    "bâtiments industriels) ne biaisent l’analyse des prix et des surfaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a497543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage des biens résidentiels : maisons et appartements uniquement\n",
    "df = df[df[\"Type local\"].isin([\"Maison\", \"Appartement\"])]\n",
    "\n",
    "# Vérification après filtrage\n",
    "df[\"Type local\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34aab4",
   "metadata": {},
   "source": [
    "## 2. Variable cible et analyse descriptive\n",
    "\n",
    "Dans ce projet, nous cherchons à expliquer et à prédire le niveau des prix immobiliers à partir des caractéristiques des biens et de leur environnement.\n",
    "\n",
    "Nous avons choisi comme **variable cible** le **prix au mètre carré**, noté *Valeur m2*, plutôt que la valeur foncière totale.\n",
    "\n",
    "Ce choix s’explique par plusieurs raisons :\n",
    "\n",
    "- le prix au mètre carré permet de comparer des biens de tailles différentes sur une base homogène ;\n",
    "- il neutralise l’effet mécanique de la surface sur le prix total ;\n",
    "- il est largement utilisé dans les analyses immobilières (agents immobiliers, notaires, études économiques) ;\n",
    "- il est plus pertinent pour analyser les variations spatiales et structurelles des prix.\n",
    "\n",
    "Le prix au mètre carré est alors défini comme le rapport entre la valeur foncière et la surface réelle bâtie du bien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CALCUL DU PRIX AU MÈTRE CARRÉ ---\n",
    "\n",
    "df[\"Valeur m2\"] = df[\"Valeur fonciere\"] / df[\"Surface reelle bati\"]\n",
    "\n",
    "# --- VÉRIFICATION DE COHÉRENCE DU M2 ET DE LA SURFACE DU BÂTI ---\n",
    "\n",
    "print(df[\"Valeur m2\"].describe(),df[\"Surface reelle bati\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55722e6",
   "metadata": {},
   "source": [
    "### 2.1 Choix du prix au mètre carré\n",
    "\n",
    "L’analyse de la distribution du prix au mètre carré met en évidence la présence de valeurs extrêmes irréalistes, aussi bien très faibles que très élevées.\n",
    "\n",
    "Nous remarquons le même problème avec la surface du bâti.\n",
    "\n",
    "Ces observations correspondent à des anomalies de la base DVF ou à des biens atypiques.\n",
    "\n",
    "Afin d’améliorer la lisibilité des graphiques et d’éviter que ces valeurs ne dominent l’analyse descriptive, nous appliquons un filtrage statistique basé sur les quantiles.\n",
    "\n",
    "Concrètement, nous conservons uniquement les observations comprises entre les quantiles 5 % et 95 % du prix au mètre carré.  \n",
    "Ce filtrage est utilisé uniquement pour l’exploration des données et n’affecte pas le jeu de données utilisé pour la modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des seuils 3 % et 97 % du prix au m²\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "df_eda = df\n",
    "\n",
    "for X in [\"Valeur m2\", \"Surface reelle bati\"] :\n",
    "    q_low = df_eda[X].quantile(0.03)\n",
    "    q_high = df_eda[X].quantile(0.97)\n",
    "    df_eda = df_eda[(df_eda[X] >= q_low) & (df_eda[X] <= q_high)]\n",
    "\n",
    "# Vérification rapide\n",
    "print(df_eda[\"Valeur m2\"].describe(),df_eda[\"Surface reelle bati\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b38efd",
   "metadata": {},
   "source": [
    "### 2.2 Distribution du prix au m²\n",
    "\n",
    "Nous commençons par analyser la distribution du prix au mètre carré (*Valeur m2*) sur les données stabilisées pour l’analyse descriptive.\n",
    "\n",
    "Cette étape permet de :\n",
    "- vérifier les ordres de grandeur ;\n",
    "- observer la dispersion des prix ;\n",
    "- identifier d’éventuelles asymétries de la distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme du prix au m²\n",
    "df_eda[\"Valeur m2\"].plot.hist(\n",
    "    bins=50,\n",
    "    edgecolor=\"black\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot du prix au m²\n",
    "df_eda.boxplot(column=\"Valeur m2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ef722",
   "metadata": {},
   "source": [
    "> La présence de nombreux outliers à la hausse reflète la forte hétérogénéité du marché immobilier, avec des biens situés dans des zones très tendues ou atypiques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3556b73",
   "metadata": {},
   "source": [
    "### 2.3 Effets structurels du logement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a7a56",
   "metadata": {},
   "source": [
    "#### Effet taille : relation entre surface et prix au mètre carré\n",
    "\n",
    "Nous étudions maintenant la relation entre la surface réelle bâtie et le prix au mètre carré.\n",
    "\n",
    "En immobilier, il est courant d’observer un **effet taille** :\n",
    "à mesure que la surface augmente, le prix au m² tend à diminuer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuage de points : surface bâtie vs prix au m²\n",
    "df_eda.plot.scatter(\n",
    "    x=\"Surface reelle bati\",\n",
    "    y=\"Valeur m2\",\n",
    "    alpha=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f477e15",
   "metadata": {},
   "source": [
    "#### Comparaison maisons vs appartements\n",
    "\n",
    "Nous comparons maintenant les prix au mètre carré entre maisons et appartements.\n",
    "Ces deux types de biens obéissent à des logiques de marché différentes,\n",
    "ce qui peut expliquer des niveaux de prix et des effets taille distincts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c917c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot du prix au m² par type de bien\n",
    "df_eda.boxplot(\n",
    "    column=\"Valeur m2\",\n",
    "    by=\"Type local\",\n",
    "    grid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c21f3",
   "metadata": {},
   "source": [
    "> Le boxplot montre une différence nette de niveau de prix entre appartements et maisons.\n",
    "Les appartements présentent un prix au mètre carré médian plus élevé et une dispersion plus importante, ce qui reflète leur localisation plus fréquente en zones urbaines tendues.\n",
    "Cette observation justifie l’intégration du type de bien comme variable explicative clé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe4383",
   "metadata": {},
   "source": [
    "## 3. Modélisations sans localisation fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566a86f",
   "metadata": {},
   "source": [
    "### 3.1 Première régression linéaire\n",
    "\n",
    "Nous estimons une régression linéaire afin d’expliquer le prix au mètre carré (*Valeur m2*)\n",
    "à partir de caractéristiques intrinsèques du logement.\n",
    "\n",
    "Variables explicatives retenues :\n",
    "- la surface réelle bâtie (effet taille) ;\n",
    "- le type de bien (maison ou appartement) ;\n",
    "- le nombre de pièces principales.\n",
    "\n",
    "Remarque : notre jeu de données ne couvre que l’année 2025, donc nous n’introduisons pas de variable temporelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcae4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d750943",
   "metadata": {},
   "source": [
    "#### Préparation des données pour la régression\n",
    "\n",
    "Nous créons une variable binaire pour représenter le type de bien :\n",
    "- Appartement = 1\n",
    "- Maison = 0\n",
    "\n",
    "Nous sélectionnons ensuite les variables explicatives et la variable cible.\n",
    "Enfin, nous supprimons les lignes avec valeurs manquantes pour éviter les erreurs lors de l’entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()\n",
    "\n",
    "# Encodage du type de bien : 1 si appartement, 0 si maison\n",
    "df_model[\"Appartement\"] = (df_model[\"Type local\"] == \"Appartement\").astype(int)\n",
    "\n",
    "df_model_clean = df_model[[\"Surface reelle bati\", \"Appartement\", \"Nombre pieces principales\",\"Valeur m2\"]].dropna() # Suppression des lignes contenant au moins une valeur manquante\n",
    "print(df_model.shape[0]-df_model_clean.shape[0])\n",
    "\n",
    "X = df_model_clean[[\"Surface reelle bati\", \"Appartement\", \"Nombre pieces principales\"]]\n",
    "y = df_model_clean[\"Valeur m2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76643003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation train / test (80 % / 20 %), avec une graine fixe pour la reproductibilité\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train1, y_train1)\n",
    "\n",
    "# Prédictions sur les données de test\n",
    "y_pred1 = model.predict(X_test1)\n",
    "\n",
    "print(r2_score(y_test1, y_pred1))\n",
    "print(mean_absolute_error(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f4d1d",
   "metadata": {},
   "source": [
    "On remarque que le modèle *naïf* de régression linéaire par rapport aux propriétés intrinsèques du logement est peu pertinent.\n",
    "\n",
    "Pour que le résultat soit plus visuel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a4630",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.Series(\n",
    "    model.coef_,\n",
    "    index=X.columns,\n",
    ")\n",
    "coefficients[\"Intercept\"] = model.intercept_\n",
    "\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40790c94",
   "metadata": {},
   "source": [
    "### 3.2 Spécification logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation logarithmique\n",
    "X_log = X.copy()\n",
    "X_log[\"Surface reelle bati\"] = np.log(X_log[\"Surface reelle bati\"])\n",
    "y_log = np.log(y)\n",
    "\n",
    "# On refait la même chose que tout à l'heure\n",
    "X_train1_log, X_test1_log, y_train1_log, y_test1_log = train_test_split(\n",
    "    X_log, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train1_log, y_train1_log)\n",
    "\n",
    "print(r2_score(y_test1_log, model.predict(X_test1_log)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27544ec6",
   "metadata": {},
   "source": [
    "> En passant à une spécification logarithmique, le pouvoir explicatif du modèle augmente nettement.\n",
    "Le R² atteint environ 10 %, ce qui confirme que les caractéristiques intrinsèques du logement expliquent une partie non négligeable du prix au mètre carré.\n",
    "La part restante s’explique principalement par la localisation, que nous introduirons dans un second temps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d55531c",
   "metadata": {},
   "source": [
    "## 4. Introduction de la localisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e93d54",
   "metadata": {},
   "source": [
    "### 4.1 Localisation grossière : département\n",
    "\n",
    "Avant d’introduire une localisation fine (coordonnées, distances), nous ajoutons\n",
    "une variable géographique simple : le **département**.\n",
    "\n",
    "Le département permet de capter des différences régionales de prix\n",
    "(tension du marché, attractivité, niveau de vie),\n",
    "tout en restant une information grossière et facile à interpréter.\n",
    "\n",
    "Cette étape permet de mesurer l’apport de la localisation\n",
    "par rapport à un modèle basé uniquement sur les caractéristiques du logement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca30e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_2 = df_model.copy()\n",
    "\n",
    "df_model_2[\"Code departement\"] = df_model_2[\"Code departement\"].astype(str) # important pour traiter correctement des codes comme 01, 2A, 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b39d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des variables indicatrices pour les départements \n",
    "departement_dummies = pd.get_dummies(\n",
    "    df_model_2[\"Code departement\"],\n",
    "    prefix=\"Dep\",\n",
    "    drop_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a5f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On refait les mêmes manipulations\n",
    "\n",
    "df_model_2_clean = df_model_2[[\"Surface reelle bati\", \"Appartement\", \"Nombre pieces principales\",\"Valeur m2\",\"Code departement\"]].dropna()\n",
    "print(df_model.shape[0]-df_model_clean.shape[0])\n",
    "\n",
    "X_num = df_model_2[[\"Surface reelle bati\", \"Appartement\", \"Nombre pieces principales\",\"Code departement\"]]\n",
    "X_num = pd.concat([X_num, departement_dummies], axis=1)\n",
    "X_num = X_num.drop(\"Code departement\",axis=1)\n",
    "# X_num.sample(n=5)\n",
    "\n",
    "X_num[\"Surface reelle bati\"] = np.log(X_num[\"Surface reelle bati\"])\n",
    "y_num = np.log(df_model_2_clean[\"Valeur m2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X_num, y_num, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train2, y_train2)\n",
    "\n",
    "print(r2_score(y_test2, model.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873cf4cc",
   "metadata": {},
   "source": [
    "L’ajout du département améliore fortement le pouvoir explicatif du modèle ($R^2$ = 26%).\n",
    "Cela confirme que la localisation explique une part majeure des différences\n",
    "de prix au mètre carré.\n",
    "\n",
    "Cette variable capte des effets régionaux (tension du marché, attractivité),\n",
    "sans recourir à une localisation fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35934b",
   "metadata": {},
   "source": [
    "### 4.2 Variables départementales issues du scraping\n",
    "\n",
    "Afin d’enrichir la base DVF avec des informations de contexte géographique,\n",
    "nous construisons une base de données départementale à partir d’un **scraping de Wikipédia**.\n",
    "\n",
    "L’objectif est de récupérer, pour chaque département français :\n",
    "- le code INSEE ;\n",
    "- le nom du département ;\n",
    "- la préfecture ;\n",
    "- la population ;\n",
    "- la densité de population.\n",
    "\n",
    "Ces variables permettent de capter des effets macro-géographiques\n",
    "(niveau d’urbanisation, pression démographique),\n",
    "sans recourir à une localisation fine.\n",
    "\n",
    "Nous utilisons Wikipédia comme source car les informations sont publiques et structurées sous forme de tableaux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import re\n",
    "\n",
    "# 1. RÉCUPÉRATION DES DONNÉES\n",
    "\n",
    "url = \"https://fr.wikipedia.org/wiki/Liste_des_d%C3%A9partements_fran%C3%A7ais\"\n",
    "\n",
    "# En-tête pour identifier proprement la requête HTTP, puis requête vers Wikipédia\n",
    "headers = {\"User-Agent\": \"Etudiant_DataScience_Immo/1.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Extraction du tableau HTML contenant le mot \"Densité\"\n",
    "dfs = pd.read_html(io.StringIO(response.text), match=\"Densité\")\n",
    "df_dept = dfs[0].copy()\n",
    "\n",
    "\n",
    "# 2. SÉLECTION ET RENOMMAGE DES COLONNES UTILES\n",
    "\n",
    "df_final = df_dept.iloc[:, [0, 1, 2, 11, 12]].copy()\n",
    "\n",
    "df_final.columns = [\n",
    "    'Code_Insee',\n",
    "    'Département',\n",
    "    'Préfecture',\n",
    "    'Population_Dept',\n",
    "    'Densité_Dept'\n",
    "]\n",
    "\n",
    "# 3. FONCTIONS DE NETTOYAGE\n",
    "\n",
    "def clean_insee(code):\n",
    "    # Nettoie et harmonise les codes département (01, 2A, 2B, 971, etc.)\n",
    "    code = str(code).strip()\n",
    "    if '2A' in code: return '2A'\n",
    "    if '2B' in code: return '2B'\n",
    "    digits = \"\".join(filter(str.isdigit, code))\n",
    "    if digits.startswith('97'): return digits[:3]\n",
    "    if len(digits) == 3: return digits[:2]\n",
    "    return digits[:2].zfill(2)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Nettoie les noms\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "df_final['Code_Insee'] = df_final['Code_Insee'].apply(clean_insee)\n",
    "df_final['Département'] = df_final['Département'].apply(clean_text)\n",
    "df_final['Préfecture'] = df_final['Préfecture'].apply(clean_text)\n",
    "\n",
    "# Suppression des lignes parasites\n",
    "df_final = df_final[df_final['Code_Insee'] != '']\n",
    "\n",
    "# Retraitement final pour la population\n",
    "df_final['Population_Dept'] = (\n",
    "    pd.to_numeric(\n",
    "        df_final['Population_Dept'].astype(str)\n",
    "        .str.replace(r'\\D', '', regex=True)\n",
    "        .str[:-4],\n",
    "        errors='coerce'\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "df_final['Densité_Dept'] = (\n",
    "    pd.to_numeric(\n",
    "        df_final['Densité_Dept'].astype(str)\n",
    "        .str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "        .str.replace(r'\\D', '', regex=True),    \n",
    "        errors='coerce'\n",
    "    )\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Vérification finale\n",
    "print(df_final.head())\n",
    "print(df_final.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c2a48",
   "metadata": {},
   "source": [
    "#### Intégration des variables issues du scraping\n",
    "\n",
    "Nous intégrons maintenant à la base DVF les variables départementales obtenues par scraping :\n",
    "- la population du département ;\n",
    "- la densité de population.\n",
    "\n",
    "Ces variables permettent de capter des effets macro-géographiques\n",
    "(niveau d’urbanisation, pression démographique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09814621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copie du jeu de données DVF\n",
    "df_model3 = df.copy()\n",
    "df_model3[\"Code departement\"] = df_model3[\"Code departement\"].astype(str)\n",
    "\n",
    "# Jointure avec les données issues du scraping\n",
    "df_model3 = df_model3.merge(\n",
    "    df_final[[\"Code_Insee\", \"Population_Dept\", \"Densité_Dept\"]],\n",
    "    left_on=\"Code departement\",\n",
    "    right_on=\"Code_Insee\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Vérification rapide des valeurs manquantes après jointure\n",
    "df_model3[[\"Population_Dept\", \"Densité_Dept\"]].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba28d5c",
   "metadata": {},
   "source": [
    "Nous enrichissons la régression en ajoutant les variables départementales\n",
    "de population et de densité.\n",
    "\n",
    "Afin de conserver une spécification adaptée aux données immobilières,\n",
    "nous utilisons une transformation logarithmique pour les variables continues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage du type de bien\n",
    "df_model3[\"Appartement\"] = (df_model3[\"Type local\"] == \"Appartement\").astype(int)\n",
    "\n",
    "# Transformations logarithmiques\n",
    "df_model3[\"log_surface\"] = np.log(df_model3[\"Surface reelle bati\"])\n",
    "df_model3[\"log_population\"] = np.log(df_model3[\"Population_Dept\"])\n",
    "df_model3[\"log_densite\"] = np.log(df_model3[\"Densité_Dept\"])\n",
    "\n",
    "# Sélection des variables explicatives\n",
    "X = df_model3[\n",
    "    [\"log_surface\", \"Appartement\", \"Nombre pieces principales\",\n",
    "     \"log_population\", \"log_densite\"]\n",
    "]\n",
    "\n",
    "# Variable cible\n",
    "y = np.log(df_model3[\"Valeur m2\"])\n",
    "\n",
    "# Nettoyage des lignes incomplètes\n",
    "df_model3_clean = pd.concat([X, y], axis=1).dropna()\n",
    "X = df_model3_clean[X.columns]\n",
    "y = df_model3_clean[y.name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19618a8e",
   "metadata": {},
   "source": [
    "Nous estimons une nouvelle régression linéaire incluant les variables\n",
    "issues du scraping afin d’évaluer leur contribution explicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08030d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Séparation train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Entraînement du modèle\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle\n",
    "r2_scrap = r2_score(y_test, model.predict(X_test))\n",
    "r2_scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98d1ca",
   "metadata": {},
   "source": [
    "Le modèle utilisant les variables issues du scraping présente un R² inférieur à celui utilisant des indicatrices départementales.\n",
    "Cela s’explique par le fait que les dummies départementales captent l’ensemble des effets spécifiques à chaque département, tandis que la population et la densité n’en captent qu’une partie structurelle.\n",
    "En contrepartie, le modèle avec scraping est plus interprétable économiquement et permet de comprendre quels mécanismes sous-jacents expliquent les différences de prix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des coefficients estimés\n",
    "pd.Series(\n",
    "    model.coef_,\n",
    "    index=X.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318fbec0",
   "metadata": {},
   "source": [
    "La régression estimée est de type log–log, ce qui permet d’interpréter les coefficients\n",
    "comme des effets proportionnels, toutes choses égales par ailleurs.\n",
    "\n",
    "Le coefficient associé à la surface réelle bâtie est égal à **−0,44**.\n",
    "Cela signifie qu’une augmentation de 10 % de la surface d’un logement\n",
    "est associée à une baisse d’environ **4,4 %** du prix au mètre carré.\n",
    "Ce résultat met en évidence un effet taille marqué,\n",
    "traduisant des rendements décroissants de la surface,\n",
    "phénomène classique sur le marché immobilier résidentiel.\n",
    "\n",
    "Le coefficient de la variable indiquant un appartement est égal à **0,22**.\n",
    "À caractéristiques identiques, un appartement présente donc un prix au mètre carré\n",
    "environ **22 % plus élevé** qu’une maison.\n",
    "Cet effet reflète des différences structurelles de marché,\n",
    "les appartements étant plus fréquemment situés dans des zones urbaines denses et tendues.\n",
    "\n",
    "Le nombre de pièces principales a un coefficient égal à **0,04**.\n",
    "À surface donnée, une pièce supplémentaire est associée\n",
    "à une hausse d’environ **4 %** du prix au mètre carré,\n",
    "ce qui suggère qu’un logement mieux découpé ou plus fonctionnel\n",
    "est davantage valorisé.\n",
    "\n",
    "Le coefficient associé au log population départementale est égal à **0,12**.\n",
    "Une augmentation de 10 % de la population d’un département\n",
    "est donc associée à une hausse d’environ **1,2 %** du prix au mètre carré.\n",
    "Cette variable capte un effet de pression démographique et d’attractivité territoriale.\n",
    "\n",
    "Enfin, le coefficient de la densité de population est égal à **0,2**.\n",
    "Une augmentation de 10 % de la densité départementale\n",
    "est associée à une hausse d’environ **2 %** du prix au mètre carré,\n",
    "confirmant le rôle de l’urbanisation et de la rareté du foncier\n",
    "dans la formation des prix immobiliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472c135",
   "metadata": {},
   "source": [
    "## 5. Localisation fine et modèles avancés\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fbff7",
   "metadata": {},
   "source": [
    "### 5.1 Intégration des gares SNCF\n",
    "\n",
    "Nous intégrons les gares SNCF afin d’introduire une information de localisation\n",
    "liée à l’accessibilité ferroviaire.\n",
    "\n",
    "Les données utilisées proviennent du jeu de données officiel des gares SNCF,\n",
    "au format CSV.\n",
    "Dans un premier temps, nous construisons une variable simple indiquant\n",
    "si une gare est présente dans une commune, avec une représentation visuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install contextily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bde26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_json = 'gares-de-voyageurs.geojson'\n",
    "\n",
    "with open(fichier_json, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# On cible la clé 'features' qui contient la liste des gares pour manipuler avec pd\n",
    "gares = pd.json_normalize(data['features'])\n",
    "gares = gares.dropna(subset=['geometry.coordinates'])\n",
    "\n",
    "# Les colonnes qui s'appellent par ex properties.nom, geometry.coordinates sont simplifiées\n",
    "gares.columns = [c.replace('properties.', '').replace('geometry.', '') for c in gares.columns]\n",
    "\n",
    "coordinates = pd.DataFrame(gares['coordinates'].tolist(), index=gares.index)\n",
    "gares['longitude'] = coordinates[0]\n",
    "gares['latitude'] = coordinates[1]\n",
    "\n",
    "colonnes_utiles = [\n",
    "    'nom', \n",
    "    'codeinsee', \n",
    "    'latitude', \n",
    "    'longitude', \n",
    "    'segment_drg'\n",
    "    ]\n",
    "\n",
    "colonnes_finales = [c for c in colonnes_utiles if c in gares.columns]\n",
    "gares_clean = gares[colonnes_finales]\n",
    "\n",
    "print(f\"{len(gares_clean)} gares récupérées.\")\n",
    "print(gares_clean.head())\n",
    "\n",
    "gares_clean.to_csv(\"gares_sncf_final.csv\", index=False)\n",
    "df_gares_clean = pd.read_csv(\"gares_sncf_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des codes communes disposant d'au moins une gare SNCF\n",
    "communes_avec_gare = df_gares_clean[\"codeinsee\"].astype(str).unique()\n",
    "\n",
    "# Vérification rapide\n",
    "len(communes_avec_gare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ab62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation visuelle\n",
    "gdf_gares = gpd.GeoDataFrame(\n",
    "    df_gares_clean,\n",
    "    geometry=gpd.points_from_xy(df_gares_clean['longitude'], df_gares_clean['latitude']),\n",
    "    crs=\"EPSG:4326\"  # Système de coordonnées WGS84\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "gdf_gares.plot(ax=ax, color='red', markersize=5, label='Gares SNCF')\n",
    "ctx.add_basemap(ax, crs=gdf_gares.crs, source=ctx.providers.OpenStreetMap.Mapnik) # fond de carte OpenStreetMap\n",
    "plt.title(\"Carte des gares SNCF en France\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9235",
   "metadata": {},
   "source": [
    "### 5.2 Construction d’une variable d’accessibilité ferroviaire\n",
    "\n",
    "En l’absence de coordonnées géographiques précises pour les logements,\n",
    "nous utilisons l’échelle communale pour mesurer l’accessibilité ferroviaire.\n",
    "\n",
    "Nous construisons une variable binaire indiquant\n",
    "si la commune du logement dispose d’au moins une gare SNCF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec628e",
   "metadata": {},
   "source": [
    "Avant de pouvoir intégrer les gares SNCF à la base DVF, il est nécessaire\n",
    "d’harmoniser les identifiants géographiques.\n",
    "\n",
    "Dans la base DVF, la variable *Code commune* correspond uniquement\n",
    "au code communal à l’intérieur du département,\n",
    "tandis que la base des gares SNCF utilise le **code INSEE complet**\n",
    "(association du code département et du code commune).\n",
    "\n",
    "Nous reconstruisons donc, côté DVF, un **code commune au format INSEE à 5 chiffres**,\n",
    "en combinant le code département et le code commune,\n",
    "afin de rendre les deux bases homogènes et permettre une jointure correcte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e32793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonisation du code département (2 chiffres, avec zéros)\n",
    "df_model3[\"Code_Insee\"] = (\n",
    "    df_model3[\"Code_Insee\"]\n",
    "    .astype(str)\n",
    "    .str.zfill(2)\n",
    ")\n",
    "\n",
    "# Harmonisation du code commune DVF (3 chiffres, avec zéros)\n",
    "df_model3[\"Code commune\"] = (\n",
    "    df_model3[\"Code commune\"]\n",
    "    .astype(str)\n",
    "    .str.zfill(3)\n",
    ")\n",
    "\n",
    "df_model3[\"Code_INSEE\"] = df_model3[\"Code departement\"] + df_model3[\"Code commune\"]\n",
    "df_model3[\"Code_INSEE\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7263cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3[\"Code_INSEE\"] = df_model3[\"Code_INSEE\"].astype(str)\n",
    "\n",
    "# Création de la variable binaire d’accessibilité ferroviaire\n",
    "df_model3[\"gare_commune\"] = (\n",
    "    df_model3[\"Code_INSEE\"]\n",
    "    .isin(communes_avec_gare)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Vérification de la distribution\n",
    "df_model3[\"gare_commune\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f04723",
   "metadata": {},
   "source": [
    "### 5.3 Intégration de l’accessibilité ferroviaire dans le modèle\n",
    "\n",
    "Nous ajoutons la variable `gare_commune` au modèle log–log afin de mesurer\n",
    "l’apport marginal de l’accessibilité ferroviaire,\n",
    "toutes choses égales par ailleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326b3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724bb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage du type de bien\n",
    "df_model3[\"Appartement\"] = (df_model3[\"Type local\"] == \"Appartement\").astype(int)\n",
    "\n",
    "# Transformations logarithmiques\n",
    "df_model3[\"log_surface\"] = np.log(df_model3[\"Surface reelle bati\"])\n",
    "df_model3[\"log_population\"] = np.log(df_model3[\"Population_Dept\"])\n",
    "df_model3[\"log_densite\"] = np.log(df_model3[\"Densité_Dept\"])\n",
    "\n",
    "# Variables explicatives (ajout de gare_commune)\n",
    "X = df_model3[\n",
    "    [\n",
    "        \"log_surface\",\n",
    "        \"Appartement\",\n",
    "        \"Nombre pieces principales\",\n",
    "        \"log_population\",\n",
    "        \"log_densite\",\n",
    "        \"gare_commune\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "y = np.log(df_model3[\"Valeur m2\"])\n",
    "\n",
    "df_model3_clean = pd.concat([X, y], axis=1).dropna()\n",
    "X = df_model3_clean[X.columns]\n",
    "y = df_model3_clean[y.name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation\n",
    "print(r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827003a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4e27f",
   "metadata": {},
   "source": [
    "### 5.4 Modèles non linéaires (avec les mêmes variables que la dernière régression)\n",
    "\n",
    "#### 5.4.1 Random Forest\n",
    "\n",
    "Nous utilisons une Random Forest afin de capturer automatiquement\n",
    "les non-linéarités et interactions complexes entre variables.\n",
    "\n",
    "Ce modèle sert de benchmark prédictif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(r2_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434142c",
   "metadata": {},
   "source": [
    "Le modèle Random Forest présente un coefficient de détermination d’environ **41 %**, supérieur à celui des modèles linéaires testés précédemment.\n",
    "\n",
    "Cette amélioration s’explique par la capacité de la Random Forest à capturer automatiquement\n",
    "des **relations non linéaires** et des **interactions complexes** entre les variables explicatives,\n",
    "sans avoir à les spécifier explicitement.\n",
    "Contrairement à la régression linéaire, le modèle n’impose pas de forme fonctionnelle\n",
    "a priori entre les variables et le prix au mètre carré.\n",
    "\n",
    "Ce résultat met en évidence l’existence de mécanismes non linéaires dans la formation des prix immobiliers,\n",
    "en particulier dans l’interaction entre les caractéristiques intrinsèques du logement\n",
    "(surface, nombre de pièces, type de bien) et les variables macro-géographiques\n",
    "(population et densité départementales).\n",
    "\n",
    "En contrepartie, la Random Forest est moins interprétable que les modèles linéaires :\n",
    "elle permet d’améliorer la performance prédictive,\n",
    "mais au prix d’une lecture économique plus limitée des effets marginaux.\n",
    "Nous utilisons donc ce modèle comme **benchmark prédictif**,\n",
    "tandis que les modèles linéaires restent privilégiés pour l’interprétation économique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16040e",
   "metadata": {},
   "source": [
    "##### Interprétation : Importance des variables\n",
    "Bien que le Random Forest soit parfois  considéré comme une \"boîte noire\", il est possible d'interpréter son fonctionnement en analysant l'importance des variables (*Feature Importance*).\n",
    "\n",
    "Cet indicateur mesure le poids de chaque variable dans la réduction de l'impureté (variance) lors de la construction des arbres. Plus une variable est importante, plus elle contribue à la précision des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title(\"Importance des variables (Random Forest)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f1c31",
   "metadata": {},
   "source": [
    "L’analyse de l’importance des variables issue de la Random Forest met en évidence\n",
    "le rôle central de la **surface du logement**, qui apparaît comme le principal déterminant\n",
    "des prix au mètre carré.\n",
    "Ce résultat confirme que l’effet taille demeure structurant,\n",
    "y compris dans un modèle non linéaire.\n",
    "\n",
    "La **population départementale** constitue le deuxième facteur le plus important,\n",
    "soulignant l’influence majeure du contexte démographique et de l’attractivité territoriale\n",
    "sur les prix immobiliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90930947",
   "metadata": {},
   "source": [
    "#### 5.4.2 Gradient Boosting \n",
    "\n",
    "Nous estimons maintenant un modèle non linéaire de type **Gradient Boosting**\n",
    "(`HistGradientBoostingRegressor`).\n",
    "\n",
    "Ce type de modèle permet de capturer automatiquement\n",
    "des **non-linéarités** et des **interactions complexes** entre variables explicatives,\n",
    "sans imposer de forme fonctionnelle a priori.\n",
    "\n",
    "L’objectif est d’évaluer le gain en performance prédictive\n",
    "par rapport aux modèles linéaires,\n",
    "et de disposer d’un **benchmark** plus performant,\n",
    "au prix d’une interprétabilité réduite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64fdffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hgb = HistGradientBoostingRegressor(\n",
    "    max_iter=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hgb.fit(X_train, y_train)\n",
    "\n",
    "print(r2_score(y_test, hgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d93f56",
   "metadata": {},
   "source": [
    "#### 5.4.3 LightGBM\n",
    "\n",
    "Nous testons ensuite un modèle de **Gradient Boosting optimisé**, LightGBM,\n",
    "afin d’évaluer s’il permet d’améliorer encore les performances prédictives\n",
    "par rapport aux autres modèles non linéaires.\n",
    "\n",
    "LightGBM est particulièrement adapté aux jeux de données de grande taille\n",
    "et repose sur une construction efficace d’arbres de décision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349daeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "print(r2_score(y_test, lgbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8272d",
   "metadata": {},
   "source": [
    "#### 5.4.4 Interprétation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd58e6",
   "metadata": {},
   "source": [
    "Les modèles de Gradient Boosting testés, **Gradient Boosting** et **LightGBM**, affichent des $R^2$ respectifs de **37 %** et **40 %**. Bien que ces performances demeurent légèrement en deçà de celles du Random Forest (41 %), elles confirment la pertinence des approches non linéaires sur la régression classique.\n",
    "\n",
    "La convergence des scores de ces trois algorithmes autour d'un palier de 40 % témoigne de la robustesse de la modélisation : elle suggère que nous avons capturé une grande partie de l'information explicative disponible dans les variables qu'on a sélectionnées, indépendamment de l'algorithme choisi. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56cf33",
   "metadata": {},
   "source": [
    "## 6. Gamification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ddc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_communes = df_model3[[\n",
    "    \"Commune\", \n",
    "    \"Population_Dept\", \n",
    "    \"Densité_Dept\", \n",
    "    \"gare_commune\"\n",
    "]].drop_duplicates(subset=\"Commune\").set_index(\"Commune\")\n",
    "\n",
    "ref_communes.index = ref_communes.index.str.upper().str.strip()\n",
    "\n",
    "print(f\"{len(ref_communes)} villes référencées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86346f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimer_mon_bien(model):\n",
    "    print(\"Estimateur immobilier C&Y\")\n",
    "    print(\"Répondez aux questions pour estimer votre bien.\\n\")\n",
    "\n",
    "    # --- 1. COLLECTE DES INFOS UTILISATEUR ---\n",
    "    \n",
    "    while True:\n",
    "        ville_input = input(\"Dans quelle commune se situe le bien ? Si Paris, préciser l'arrondissement (uniquement le nombre)\").upper().strip()\n",
    "        \n",
    "        if ville_input in ref_communes.index:\n",
    "            infos_ville = ref_communes.loc[ville_input]\n",
    "            \n",
    "            if isinstance(infos_ville, pd.DataFrame):\n",
    "                infos_ville = infos_ville.iloc[0] # pour les homonymes\n",
    "                \n",
    "            pop_dept = infos_ville['Population_Dept']\n",
    "            densite_dept = infos_ville['Densité_Dept']\n",
    "            gare = infos_ville['gare_commune']\n",
    "            print(f\"Ville identifiée (Dept Pop: {pop_dept}, Gare: {'Oui' if gare==1 else 'Non'})\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"   Je ne connais pas '{ville_input}' ou elle n'est pas dans mon jeu de données. Essayez une autre ville.\")\n",
    "\n",
    "    type_bien = input(\"Type de bien : A pour Appartement, M pour Maison) : \").upper()\n",
    "    is_appartement = 1 if type_bien == 'A' else 0\n",
    "    \n",
    "    surface = float(input(\"Surface réelle (m²) : \"))\n",
    "    \n",
    "    pieces = int(input(\"Nombre de pièces principales : \"))\n",
    "\n",
    "    log_surface = np.log(surface)\n",
    "    log_pop = np.log(pop_dept)\n",
    "    log_densite = np.log(densite_dept)\n",
    "    \n",
    "    X_input = pd.DataFrame([[\n",
    "        log_surface,\n",
    "        is_appartement,\n",
    "        pieces,\n",
    "        log_pop,\n",
    "        log_densite,\n",
    "        gare\n",
    "    ]], columns=[\n",
    "        'log_surface', \n",
    "        'Appartement', \n",
    "        'Nombre pieces principales', \n",
    "        'log_population', \n",
    "        'log_densite', \n",
    "        'gare_commune'\n",
    "    ])\n",
    "    \n",
    "    prix_m2_estime = np.exp(model.predict(X_input)[0])\n",
    "    prix_total = prix_m2_estime * surface\n",
    "    \n",
    "    print(f\"RÉSULTAT DE L'ESTIMATION\")\n",
    "    print(f\"Prix au m² estimé : {prix_m2_estime:,.0f} €/m²\".replace(',', ' '))\n",
    "    print(f\"VALEUR TOTALE     : {prix_total:,.0f} €\".replace(',', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee8b162",
   "metadata": {},
   "source": [
    "Les modèles différents qu'on a testés et qui peuvent être utilisés :\n",
    "- model pour la dernière régression linéaire\n",
    "- rf pour le random forest\n",
    "- hgb pour le hist gradient boosting\n",
    "- lgbm pour LightGBM\n",
    "\n",
    "La fonction peut être appelée par **estimer_mon_bien(*Nom du modèle*)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27296079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimer_mon_bien(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04229358",
   "metadata": {},
   "source": [
    "## 7. Conclusion et perspectives\n",
    "\n",
    "### Bilan du projet\n",
    "Ce projet avait pour objectif de comprendre les déterminants du prix de l'immobilier résidentiel en France en 2025. En partant des données brutes DVF, nous avons progressivement complexifié nos modèles pour isoler l'impact des caractéristiques du logement et de sa localisation.\n",
    "\n",
    "Nos résultats mettent en évidence trois points majeurs :\n",
    "1.  **Le \"plafond\" des caractéristiques intrinsèques** : La surface, le nombre de pièces et le type de bien (maison/appartement) n'expliquent à eux seuls qu'environ **10 %** de la variance des prix au m².\n",
    "2.  **La domination de la localisation** : L'ajout de variables géographiques (département, densité de population, présence d'une gare) permet de tripler le pouvoir explicatif du modèle. L'analyse d'importance des variables (Feature Importance) confirme que la densité urbaine est le premier facteur de prix, devant la surface du bien.\n",
    "3.  **L'apport du Machine Learning** : Le passage aux modèles non linéaires (Random Forest, LightGBM) a permis d'atteindre un $R^2$ d'environ **41 %**, surpassant nettement la régression linéaire. Cela prouve l'existence d'interactions complexes (effets de seuil, non-linéarités) que les modèles classiques ne captent pas.\n",
    "\n",
    "### Limites de l'approche\n",
    "Malgré l'utilisation d'algorithmes avancés, environ **60 % de la variance des prix reste inexpliquée**. Cette limite est structurelle et liée à la nature de nos données :\n",
    "* **Absence de \"micro-localisation\"** : Nous travaillons à l'échelle de la commune ou du département. Or, la valeur d'un bien dépend de son adresse exacte (quartier, rue, vue, bruit).\n",
    "* **État du bien inconnu** : La base DVF ne renseigne ni l'état général (neuf/rénové/ruine), ni l'étage, ni les prestations annexes (balcon, parking, ascenseur), qui peuvent faire varier le prix de ±20 %.\n",
    "* **Qualité des données** : Le filtrage des valeurs aberrantes a été nécessaire, mais certaines erreurs de saisie dans les surfaces persistent probablement.\n",
    "\n",
    "### Pistes d'amélioration\n",
    "Pour aller plus loin et dépasser ce plafond de 41 % de précision, plusieurs pistes pourraient être explorées :\n",
    "1.  **Géolocalisation précise** : Utiliser les coordonnées exactes (latitude/longitude) de chaque transaction pour calculer des distances réelles aux points d'intérêt (écoles, métros, parcs) plutôt que d'utiliser des moyennes communales.\n",
    "2.  **Intégration du DPE** : Croiser la base DVF avec la base des Diagnostics de Performance Énergétique (ADEME) pour mesurer la \"valeur verte\" et la décote des passoires thermiques.\n",
    "3.  **Analyse temporelle** : Étendre l'étude sur 5 ans pour observer l'évolution des prix et intégrer une composante dynamique (tendance du marché local)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
